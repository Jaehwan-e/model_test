{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5b0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-02 09:38:19] INFO - checkpoint_utils.py - Successfully loaded model weights from ./model/ckpt_latest.pth EMA checkpoint.\n",
      "Predicting Images:   0%|          | 0/11 [00:00<?, ?it/s][2025-07-02 09:38:20] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_092826.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_863_2125.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_866_2241.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_870_3459.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_872_4945.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_874_5187.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_875_9829.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_877_9179.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_880_7911.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_881_8781.jpg\n",
      "âœ… Saved: ./cropped_pred\\pred_cropped_20250702_093228_884_1903.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "\n",
    "# ðŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "input_dir = \"./cropped\"\n",
    "output_dir = \"./cropped_pred\"\n",
    "ckpt_path = \"./model/ckpt_latest.pth\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = models.get(Models.YOLO_NAS_L, num_classes=2, checkpoint_path=ckpt_path)\n",
    "model.to(device)  # ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
    "\n",
    "# ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = model.predict(image_paths, conf=0.65)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥\n",
    "for img_path, prediction in zip(image_paths, predictions):\n",
    "    drawn_np = prediction.draw()\n",
    "    drawn_img = Image.fromarray(drawn_np)\n",
    "\n",
    "    filename = os.path.basename(img_path)\n",
    "    save_path = os.path.join(output_dir, f\"pred_{filename}\")\n",
    "    \n",
    "    drawn_img.save(save_path)\n",
    "    print(f\"âœ… Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa97714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
