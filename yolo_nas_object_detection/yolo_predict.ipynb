{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5b0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-02 17:05:39] INFO - checkpoint_utils.py - Successfully loaded model weights from ../model/ckpt_latest.pth EMA checkpoint.\n",
      "Predicting Images:   0%|          | 0/60 [00:00<?, ?it/s][2025-07-02 17:05:40] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
      "Predicting Images: 100%|██████████| 60/60 [00:01<00:00, 40.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_461_6716.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_462_6975.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_466_5914.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_468_5939.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_471_5750.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_472_4844.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_475_9624.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_479_4300.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_484_6139.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_487_4153.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_488_2945.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_489_6634.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_491_8353.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_494_1435.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_496_8291.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_500_3639.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_502_6021.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_505_5649.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_509_9457.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_510_2379.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_513_4541.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_517_4686.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_517_6371.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_519_2513.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_522_9430.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_523_4404.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_527_2734.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_529_1066.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_530_5254.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161448_530_8070.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_293_9491.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_295_8626.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_300_6215.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_301_1921.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_303_8199.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_305_8817.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_306_7790.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_308_2184.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_309_4517.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_311_7324.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_317_8937.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_318_7959.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_320_8474.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_323_8090.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_326_4196.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_328_4844.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_329_4366.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_333_2162.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_334_3502.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_340_8151.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_341_6869.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_345_9075.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_351_1280.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_356_4142.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_360_8670.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_364_7609.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_366_8263.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_370_3524.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_373_6957.jpg\n",
      "✅ Saved: ../data/cropped_pred\\pred_cropped_20250702_161454_374_5604.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "\n",
    "# 🔧 경로 설정\n",
    "input_dir = \"../data/cropped\"\n",
    "output_dir = \"../data/cropped_pred\"\n",
    "ckpt_path = \"../model/ckpt_latest.pth\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 불러오기\n",
    "model = models.get(Models.YOLO_NAS_L, num_classes=2, checkpoint_path=ckpt_path)\n",
    "model.to(device)  # 모델을 GPU로 이동\n",
    "\n",
    "# 이미지 목록 가져오기\n",
    "image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(image_paths, conf=0.4)\n",
    "\n",
    "# 예측 결과 저장\n",
    "for img_path, prediction in zip(image_paths, predictions):\n",
    "    drawn_np = prediction.draw()\n",
    "    drawn_img = Image.fromarray(drawn_np)\n",
    "\n",
    "    filename = os.path.basename(img_path)\n",
    "    save_path = os.path.join(output_dir, f\"pred_{filename}\")\n",
    "    \n",
    "    drawn_img.save(save_path)\n",
    "    print(f\"✅ Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa97714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
